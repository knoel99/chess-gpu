# â™Ÿ Chess-GPU â€” RÃ©sultats d'entraÃ®nement et d'Ã©valuation

> Apprendre Ã  jouer aux Ã©checs par imitation des Grands MaÃ®tres, avec un rÃ©seau de neurones
> entraÃ®nÃ© sur GPU. Ce document retrace l'intÃ©gralitÃ© de la pipeline â€” de la collecte des donnÃ©es
> Ã  l'Ã©valuation en partie rÃ©elle contre Stockfish â€” et analyse en dÃ©tail les rÃ©sultats obtenus
> lors du run du 15 fÃ©vrier 2026.

---

## 1. Vue d'ensemble du projet

### Le concept : apprendre par imitation

L'approche classique pour programmer un moteur d'Ã©checs consiste Ã  coder manuellement des
rÃ¨gles d'Ã©valuation (valeur des piÃ¨ces, structure de pions, contrÃ´le du centre, sÃ©curitÃ© du roi)
et Ã  les combiner avec un algorithme de recherche arborescente (minimax, alpha-beta). Cette
mÃ©thode a fait ses preuves â€” c'est ainsi que fonctionnent Stockfish et les moteurs traditionnels.

Notre approche est radicalement diffÃ©rente : **au lieu de coder des rÃ¨gles, on les apprend**.
On tÃ©lÃ©charge des centaines de milliers de parties jouÃ©es par les 10 meilleurs joueurs du monde
sur Chess.com, on encode chaque position de l'Ã©chiquier sous forme de vecteur numÃ©rique, et on
entraÃ®ne un rÃ©seau de neurones Ã  prÃ©dire le prochain coup â€” exactement comme un Grand MaÃ®tre
le jouerait. Le rÃ©seau n'a aucune connaissance prÃ©alable des Ã©checs : il dÃ©couvre les ouvertures,
les tactiques et les finales uniquement Ã  travers les exemples.

### La pipeline complÃ¨te

Le projet s'articule autour de quatre Ã©tapes sÃ©quentielles, chacune gÃ©rÃ©e par un module Python
dÃ©diÃ© et orchestrÃ©e par un script principal (`main.py`) :

```
1. TÃ©lÃ©chargement       2. Encodage matriciel      3. EntraÃ®nement         4. Ã‰valuation
   (download_data.py)      (prepare_data.py)           (train_torch.py)       (evaluate.py)
                                                                                    
   Chess.com API           Position â†’ vecteur         PyTorch + GPU           vs Stockfish
   10 joueurs GM           one-hot 832D               4 couches + BN          alpha-beta
   208 588 parties         17.7M exemples             batch=8192              Elo ~1350
   598.5 Mo PGN            256.9 Mo NPZ               2 min 48 s              10 parties
```

Le tout est automatisÃ© dans un script unique `run_colab.py` qui dÃ©tecte automatiquement si c'est
une premiÃ¨re exÃ©cution ou une relance, et ne rÃ©pÃ¨te que les Ã©tapes nÃ©cessaires.

---

## 2. DonnÃ©es d'entraÃ®nement

### SÃ©lection des joueurs

Nous avons sÃ©lectionnÃ© 10 Grands MaÃ®tres parmi les meilleurs joueurs du monde, en privilÃ©giant
ceux ayant un volume important de parties sur Chess.com. Les comptes ont Ã©tÃ© vÃ©rifiÃ©s un par un
contre l'API Chess.com (plusieurs pseudos initiaux renvoyaient des erreurs 404 et ont dÃ» Ãªtre
corrigÃ©s : `faaborovsky` â†’ `fabianocaruana`, `duhless` â†’ `nihalsarin`, etc.).

Le tÃ©lÃ©chargement est parallÃ©lisÃ© avec 8 workers et rÃ©cupÃ¨re l'intÃ©gralitÃ© de l'historique
de chaque joueur, tous formats confondus (Bullet, Blitz, Rapid, Daily).

| # | Joueur | Elo FIDE (pic) | Compte Chess.com | Mois d'archives | Parties | Taille PGN |
|---|--------|---------------|------------------|-----------------|---------|------------|
| 1 | Magnus Carlsen | 2882 | `magnuscarlsen` | 59 | 9 092 | 27 Mo |
| 2 | Hikaru Nakamura | 2816 | `hikaru` | 146 | 67 411 | 191 Mo |
| 3 | Fabiano Caruana | 2844 | `fabianocaruana` | 96 | ~8 000 | 20 Mo |
| 4 | Ian Nepomniachtchi | 2795 | `lachesisq` | 94 | ~11 000 | 27 Mo |
| 5 | Alireza Firouzja | 2804 | `firouzja2003` | 79 | ~45 000 | 109 Mo |
| 6 | Nihal Sarin | 2694 | `nihalsarin` | 166 | ~65 000 | 160 Mo |
| 7 | Praggnanandhaa | 2747 | `rpragchess` | 104 | ~12 000 | 28 Mo |
| 8 | Maxime Vachier-Lagrave | 2819 | `lyonbeast` | 114 | ~8 000 | 19 Mo |
| 9 | Alexander Grischuk | 2810 | `grischuk` | 92 | ~7 000 | 16 Mo |
| 10 | Anish Giri | 2798 | `anishgiri` | 63 | ~2 500 | 5.5 Mo |

> **Note :** Hikaru Nakamura et Nihal Sarin dominent largement en volume car ils sont
> des streameurs trÃ¨s actifs sur Chess.com, jouant des dizaines de parties par jour en Bullet
> et Blitz. Cela signifie que le modÃ¨le sera biaisÃ© vers leur style de jeu â€” rapide et tactique
> plutÃ´t que positionnel.

### Volume total des donnÃ©es

| MÃ©trique | Valeur |
|----------|--------|
| Fichier PGN fusionnÃ© | **598.5 Mo** |
| Parties individuelles parsÃ©es | **208 588** |
| Positions encodÃ©es (exemples d'entraÃ®nement) | **17 730 038** |
| Coups uniques dans le dictionnaire (tokens) | **1 968** |
| Fichier NPZ compressÃ© (donnÃ©es encodÃ©es) | **256.9 Mo** |
| Coups moyen par partie | **~85** (170 demi-coups) |

### Encodage des positions : le vecteur one-hot 832D

Chaque position de l'Ã©chiquier est convertie en un vecteur binaire de **832 dimensions**.
L'Ã©chiquier comporte 64 cases, et chaque case peut contenir l'une de 13 catÃ©gories : vide (0),
ou l'un des 6 types de piÃ¨ces (pion, cavalier, fou, tour, dame, roi) Ã— 2 couleurs (blanc, noir).
On encode donc chaque case en one-hot sur 13 bits, ce qui donne 64 Ã— 13 = 832 dimensions.

```
Exemple : case e1 contient un Roi blanc
  â†’ 13 bits : [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
                                  â†‘ index 6 = Roi blanc

Position complÃ¨te : concatÃ©nation des 64 cases
  â†’ vecteur (832,) de 0 et de 1
```

Cette reprÃ©sentation est **simple mais limitÃ©e** : elle ne capture ni le tour de jeu
(blanc ou noir), ni les droits de roque, ni la possibilitÃ© de prise en passant, ni l'historique
des coups. Ces informations supplÃ©mentaires sont des pistes d'amÃ©lioration identifiÃ©es.

La fonction `board_to_vector()` a Ã©tÃ© optimisÃ©e pour utiliser `piece_map()` de python-chess,
qui ne retourne que les cases occupÃ©es (~20 Ã  32 piÃ¨ces en milieu de partie), au lieu de
parcourir les 64 cases systÃ©matiquement avec `piece_at()`.

### Le dictionnaire de coups (1 968 tokens)

Tous les coups possibles aux Ã©checs sont Ã©numÃ©rÃ©s Ã  l'avance dans un dictionnaire de **1 968 tokens**.
Chaque token est un triplet `(case_dÃ©part, case_arrivÃ©e, promotion)`. Ce dictionnaire couvre
tous les dÃ©placements lÃ©gaux de toutes les piÃ¨ces (incluant les 4 types de promotion pour les pions).
Le rÃ©seau prÃ©dit une distribution de probabilitÃ© sur ces 1 968 tokens, puis on filtre les coups
illÃ©gaux dans la position courante.

### Optimisations du parsing

Le parsing de 208 588 parties (598.5 Mo de PGN) Ã©tait initialement un goulot d'Ã©tranglement majeur.
Deux optimisations ont rÃ©duit le temps de **~80 minutes Ã  86 secondes** :

| Optimisation | Avant | AprÃ¨s | Gain |
|---|---|---|---|
| Parsing PGN parallÃ¨le (ProcessPoolExecutor, 8 workers) | ~80 min sÃ©quentiel | **86 s** parallÃ¨le | **56Ã—** |
| `board_to_vector()` avec `piece_map()` au lieu de `piece_at()` | 64 appels/position | ~25 appels/position | **~2.5Ã—** |

Le PGN est d'abord dÃ©coupÃ© en textes de parties individuelles (`_split_pgn`), puis distribuÃ©
en batches aux workers. Chaque worker parse ses parties indÃ©pendamment avec python-chess et
retourne les vecteurs encodÃ©s. Un point technique important : la fonction de parsing (`_parse_batch`)
a dÃ» Ãªtre dÃ©finie au niveau module (et non comme fonction locale) car `ProcessPoolExecutor`
utilise `pickle` pour la communication inter-processus, et pickle ne peut pas sÃ©rialiser les
fonctions imbriquÃ©es.

---

## 3. Architecture du rÃ©seau

### ChessNet â€” Perceptron multi-couches Ã  4 couches

Le modÃ¨le est un MLP (Multi-Layer Perceptron) classique Ã  4 couches linÃ©aires, avec
Batch Normalization, ReLU et Dropout entre chaque couche cachÃ©e. C'est une architecture
intentionnellement simple â€” l'objectif est d'Ã©tablir une baseline solide avant d'explorer
des architectures plus sophistiquÃ©es (CNN, Transformer).

```
EntrÃ©e (832)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Position de l'Ã©chiquier (one-hot)
    â”‚
    â”œâ”€â”€ Linear(832 â†’ 1024)                   PremiÃ¨re couche cachÃ©e
    â”œâ”€â”€ BatchNorm1d(1024)                    Normalisation pour stabiliser l'entraÃ®nement
    â”œâ”€â”€ ReLU                                 Activation non-linÃ©aire
    â”œâ”€â”€ Dropout(0.3)                         RÃ©gularisation (30% des neurones dÃ©sactivÃ©s)
    â”‚
    â”œâ”€â”€ Linear(1024 â†’ 512)                   DeuxiÃ¨me couche cachÃ©e
    â”œâ”€â”€ BatchNorm1d(512)
    â”œâ”€â”€ ReLU
    â”œâ”€â”€ Dropout(0.3)
    â”‚
    â”œâ”€â”€ Linear(512 â†’ 256)                    TroisiÃ¨me couche cachÃ©e
    â”œâ”€â”€ BatchNorm1d(256)
    â”œâ”€â”€ ReLU
    â”œâ”€â”€ Dropout(0.3)
    â”‚
    â””â”€â”€ Linear(256 â†’ 1968)                   Couche de sortie
         â””â”€â”€ Softmax â†’ probabilitÃ© de chaque coup dans le dictionnaire
```

### HyperparamÃ¨tres d'entraÃ®nement

| ParamÃ¨tre | Valeur | Justification |
|-----------|--------|---------------|
| Optimizer | Adam (lr=1e-3, wd=1e-5) | Convergence rapide, weight decay lÃ©ger contre l'overfitting |
| Scheduler | CosineAnnealing â†’ 1e-6 | RÃ©duit le LR progressivement pour affiner la convergence |
| Batch size | **8 192** (auto-tunÃ©) | AdaptÃ© automatiquement selon la VRAM disponible (512 sur T4, 8192 sur RTX 6000) |
| Epochs | 50 (patience=10) | Early stopping si la val loss ne baisse plus pendant 10 epochs |
| Dropout | 0.3 | Compromis standard entre rÃ©gularisation et capacitÃ© d'apprentissage |
| ParamÃ¨tres totaux | **2 018 480** (7.7 Mo) | ModÃ¨le compact : 832Ã—1024 + 1024Ã—512 + 512Ã—256 + 256Ã—1968 + biais + BN |
| Train/Val split | 90% / 10% | 15.96M exemples d'entraÃ®nement, 1.77M de validation |

### Format d'export du modÃ¨le

Le modÃ¨le entraÃ®nÃ© est exportÃ© dans deux formats :
- **`.pt` (PyTorch checkpoint)** : sauvegardÃ© en premier comme filet de sÃ©curitÃ©, contient le `state_dict` complet,
  la config, et l'historique d'entraÃ®nement. Permet de reprendre l'entraÃ®nement.
- **`.npz` (NumPy)** : format lÃ©ger (7.2 Mo) utilisÃ© par l'Ã©valuateur. Contient les poids de chaque couche
  (`W0..W3`, `b0..b3`), les paramÃ¨tres BatchNorm (`bn0_weight`, `bn0_running_mean`, etc.) et le dictionnaire
  de coups (`move_tokens`). Ce format permet l'infÃ©rence avec NumPy (CPU) ou CuPy (GPU) sans dÃ©pendre de PyTorch.

---

## 4. EntraÃ®nement

### Configuration matÃ©rielle

L'entraÃ®nement a Ã©tÃ© rÃ©alisÃ© sur Google Colab avec le GPU suivant :

| Composant | DÃ©tail |
|-----------|--------|
| GPU | **NVIDIA RTX PRO 6000 Blackwell Server Edition** |
| VRAM totale | **95 Go** (97 887 MiB) |
| VRAM utilisÃ©e | **58 Go** (59% â€” dataset complet chargÃ© sur GPU) |
| Puissance consommÃ©e | **300-365 W** sur 600 W max (50-60% du TDP) |
| TempÃ©rature | **44-49Â°C** (refroidissement serveur efficace) |
| GPU utilization | **74-85%** |
| Driver | NVIDIA 580.82.07 / CUDA 13.0 |
| Python | 3.12 |
| PyTorch | 2.0+ avec CUDA, AMP, torch.compile |

### Optimisations GPU â€” de 53s Ã  2.9s par epoch

L'entraÃ®nement initial avec les paramÃ¨tres par dÃ©faut (batch_size=512, DataLoader CPU) n'utilisait
que **1.1 Go de VRAM sur 95 Go** et le GPU tournait Ã  **0-8% d'utilisation**. Le goulot d'Ã©tranglement
Ã©tait le transfert CPUâ†’GPU : le DataLoader devait copier chaque batch de la RAM vers la VRAM Ã  chaque
itÃ©ration, et le GPU passait l'essentiel de son temps Ã  attendre les donnÃ©es.

Cinq optimisations successives ont rÃ©duit le temps par epoch de **53 secondes Ã  2.9 secondes** (18Ã— plus rapide) :

| # | Technique | Impact | Explication |
|---|-----------|--------|-------------|
| 1 | **Dataset complet sur VRAM** | VRAM 1â†’58 Go, GPU 8â†’78% | Les 17.7M exemples en float32 font ~55 Go â€” ils tiennent intÃ©gralement dans les 95 Go de VRAM. Plus aucun transfert CPUâ†’GPU pendant l'entraÃ®nement. On itÃ¨re avec `torch.randperm` et de l'indexation GPU directe au lieu d'un DataLoader. |
| 2 | **Batch size auto-tunÃ©** | 512â†’8192 | Le batch_size est adaptÃ© automatiquement selon la VRAM : 8192 pour â‰¥40 Go, 4096 pour â‰¥16 Go, 2048 pour â‰¥8 Go. Les gros batch saturent les milliers de cores CUDA du GPU. |
| 3 | **AMP Mixed Precision (float16)** | ~2Ã— plus rapide | Les Tensor Cores du GPU calculent beaucoup plus vite en float16 qu'en float32. Le `GradScaler` ajuste dynamiquement l'Ã©chelle des gradients pour Ã©viter les underflows. |
| 4 | **`torch.compile`** | Fusion de kernels | PyTorch 2.0 compile le graphe de calcul en kernels CUDA optimisÃ©s, Ã©liminant les launches de kernels individuels. |
| 5 | **`cudnn.benchmark`** | Auto-tune des convolutions | cuDNN teste plusieurs algorithmes Ã  la premiÃ¨re itÃ©ration et sÃ©lectionne le plus rapide pour les dimensions utilisÃ©es. |

**RÃ©sultat :** 50 epochs Ã— 2.9s = **2 min 48 s** d'entraÃ®nement total (au lieu de ~44 min avec les paramÃ¨tres initiaux).

### Monitoring GPU en temps rÃ©el

Le monitoring GPU a Ã©tÃ© rÃ©alisÃ© avec un script de monitoring continu dans une cellule Colab sÃ©parÃ©e,
interrogeant `nvidia-smi` toutes les 5 secondes. Voici un extrait typique pendant l'entraÃ®nement :

```
     Heure â”‚ GPU % â”‚       VRAM MiB â”‚      Power W â”‚  Temp
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  17:52:48 â”‚   78% â”‚  58091/ 97887 â”‚ 308.49/600.00 â”‚   41Â°C
  17:52:53 â”‚   78% â”‚  58091/ 97887 â”‚ 364.55/600.00 â”‚   44Â°C
  17:53:08 â”‚   77% â”‚  58091/ 97887 â”‚ 323.52/600.00 â”‚   44Â°C
  17:53:18 â”‚   77% â”‚  58091/ 97887 â”‚ 320.71/600.00 â”‚   46Â°C
  17:54:08 â”‚   77% â”‚  58091/ 97887 â”‚ 316.45/600.00 â”‚   47Â°C
  17:54:53 â”‚   77% â”‚  58091/ 97887 â”‚ 317.57/600.00 â”‚   48Â°C
```

### Courbes d'entraÃ®nement

![Courbes d'entraÃ®nement](training_curves.png)

Le tableau ci-dessous dÃ©taille l'Ã©volution epoch par epoch. Toutes les 50 epochs ont amÃ©liorÃ©
la validation loss (â˜… Ã  chaque epoch), ce qui signifie que le modÃ¨le n'a pas du tout overfittÃ©
et qu'il y a encore de la marge d'amÃ©lioration avec plus d'epochs.

| Epoch | Train Loss | Val Loss | Top-1 Acc | Top-5 Acc | LR | DurÃ©e |
|-------|-----------|----------|-----------|-----------|-----|-------|
| 1 | 4.6879 | 3.8459 | 18.3% | 40.5% | 1.0e-03 | 6.7s â˜… |
| 2 | 4.2600 | 3.6837 | 19.7% | 43.0% | 1.0e-03 | 2.9s â˜… |
| 3 | 4.1419 | 3.5967 | 20.4% | 44.3% | 1.0e-03 | 2.9s â˜… |
| 5 | 4.0104 | 3.4933 | 21.2% | 45.9% | 9.8e-04 | 2.9s â˜… |
| 10 | 3.8581 | 3.3715 | 22.3% | 48.1% | 9.2e-04 | 2.9s â˜… |
| 15 | 3.7901 | 3.3091 | 23.0% | 49.3% | 8.2e-04 | 2.9s â˜… |
| 20 | 3.7472 | 3.2693 | 23.4% | 50.0% | 6.8e-04 | 2.9s â˜… |
| 25 | 3.7135 | 3.2391 | 23.7% | 50.7% | 5.3e-04 | 2.9s â˜… |
| 30 | 3.6837 | 3.2121 | 24.1% | 51.3% | 3.8e-04 | 2.8s â˜… |
| 35 | 3.6566 | 3.1882 | 24.4% | 51.8% | 2.3e-04 | 2.8s â˜… |
| 40 | 3.6329 | 3.1704 | 24.6% | 52.2% | 1.2e-04 | 2.8s â˜… |
| 45 | 3.6180 | 3.1593 | 24.7% | 52.4% | 3.6e-05 | 2.9s â˜… |
| **50** | **3.6117** | **3.1548** | **24.8%** | **52.5%** | 2.0e-06 | 2.8s â˜… |

**DurÃ©e totale d'entraÃ®nement : 2 min 48 s**

### InterprÃ©tation des mÃ©triques

**Top-1 accuracy = 24.8%** signifie que le rÃ©seau joue exactement le mÃªme coup qu'un Grand MaÃ®tre
dans 24.8% des positions. Avec 1 968 coups possibles dans le dictionnaire, le hasard donnerait
~0.05%, donc le rÃ©seau est **496Ã— meilleur que le hasard**. Cela dit, se tromper 3 fois sur 4
est insuffisant pour jouer correctement aux Ã©checs, car une seule erreur tactique peut coÃ»ter la partie.

**Top-5 accuracy = 52.5%** signifie que le coup du GM figure parmi les 5 meilleurs prÃ©dictions
du rÃ©seau une fois sur deux. C'est encourageant car cela montre que le rÃ©seau a bien captÃ© les
grandes tendances stratÃ©giques â€” il propose gÃ©nÃ©ralement des coups raisonnables, mÃªme s'il ne
trouve pas toujours le meilleur.

**Pas d'overfitting :** la train loss (3.61) reste supÃ©rieure Ã  la val loss (3.15) sur les
50 epochs, avec un Ã©cart stable (~0.46). Cela indique que le modÃ¨le a encore de la capacitÃ©
d'apprentissage et bÃ©nÃ©ficierait de plus d'epochs ou d'un rÃ©seau plus large. Le early stopping
(patience=10) n'a jamais Ã©tÃ© dÃ©clenchÃ©.

**Convergence du cosine annealing :** le learning rate passe de 1e-3 Ã  2e-6 sur 50 epochs.
Les gains sont rapides au dÃ©but (18.3% â†’ 22.3% en 10 epochs) puis ralentissent progressivement
(22.3% â†’ 24.8% sur les 40 epochs restantes). Un redÃ©marrage du cosine annealing sur 100-200 epochs
supplÃ©mentaires pourrait dÃ©bloquer 2-3% de top-1 en plus.

---

## 5. Ã‰valuation vs Stockfish

### Protocole d'Ã©valuation

Le modÃ¨le est Ã©valuÃ© en jouant des parties complÃ¨tes contre **Stockfish 14**, limitÃ© Ã  un Elo
de **~1350** (niveau club amateur intermÃ©diaire). Chaque Ã©valuation comprend 10 parties, le modÃ¨le
alternant entre les Blancs et les Noirs. Stockfish dispose de 0.1 seconde par coup.

L'Ã©valuation est rÃ©alisÃ©e avec le backend **CuPy** (GPU) pour l'infÃ©rence du rÃ©seau, et
**8 threads parallÃ¨les** pour jouer plusieurs parties simultanÃ©ment. Un lock GPU sÃ©rialise les
appels CuPy (qui n'est pas thread-safe).

### Modes d'Ã©valuation

| Mode | Description | ParamÃ¨tres |
|------|-------------|------------|
| **InstantanÃ©** | Le rÃ©seau joue directement le coup ayant la plus haute probabilitÃ© parmi les coups lÃ©gaux. Pas de recherche, pas d'anticipation. | `--games 10` |
| **Recherche Î±-Î²** | Recherche alpha-beta avec iterative deepening. Le rÃ©seau gÃ©nÃ¨re les candidats (top-k par probabilitÃ©), la recherche explore l'arbre de jeu. Un budget global de nÅ“uds limite la durÃ©e. | `--games 10 --max-depth 4 --max-nodes 1000` |
| **Benchmark** | Joue les mÃªmes 10 parties dans les deux modes et compare les rÃ©sultats cÃ´te Ã  cÃ´te. | `--games 10 --benchmark --max-depth 4 --max-nodes 1000` |

### RÃ©sultats dÃ©taillÃ©s

#### Mode instantanÃ© (15 fÃ©vrier 2026, 17:55:26)

| Partie | Couleur | RÃ©sultat | Demi-coups | Observation |
|--------|---------|----------|------------|-------------|
| G01 | â¬œ Blancs | âŒ DÃ©faite | ~212 | Longue fin de partie, le rÃ©seau joue sans but |
| G02 | â¬› Noirs | âŒ DÃ©faite | ~187 | Stockfish obtient 2 dames (Î”+18), mat inÃ©vitable |
| G03 | â¬œ Blancs | âŒ DÃ©faite | ~302 | Partie trÃ¨s longue, le rÃ©seau ne conclut jamais |
| G04 | â¬› Noirs | âŒ DÃ©faite | ~71 | Ã‰crasÃ© rapidement, matÃ©riel Î”+20 pour Stockfish |
| G05 | â¬œ Blancs | âŒ DÃ©faite | ~167 | Perd du matÃ©riel progressivement |
| G06 | â¬› Noirs | âŒ DÃ©faite | ~23 | Mat en 15 coups â€” tactique ratÃ©e |
| G07 | â¬œ Blancs | âŒ DÃ©faite | ~247 | Le rÃ©seau survit longtemps mais sans plan |
| G08 | â¬› Noirs | âŒ DÃ©faite | ~51 | DÃ©faite rapide |
| G09 | â¬œ Blancs | âŒ DÃ©faite | ~137 | MatÃ©riel Î”-16 en fin de partie |
| G10 | â¬› Noirs | ğŸ¤ Nulle | ~150 | Seule nulle â€” position simplifiÃ©e |

**Score : 0W - 1D - 9L = 0.5/10 (5%) â€” Elo estimÃ© : ~838**

#### Mode recherche Î±-Î² (15 fÃ©vrier 2026, 17:55:37)

| Partie | Couleur | RÃ©sultat | Demi-coups | NÅ“uds typiques/coup | Observation |
|--------|---------|----------|------------|---------------------|-------------|
| G01 | â¬œ Blancs | ğŸ¤ Nulle | ~200 | 60-145 | MatÃ©riel Ã©gal (3v3), 200 coups sans conclusion |
| G02 | â¬› Noirs | âŒ DÃ©faite | ~88 | 26-51 | Mat forcÃ© par Stockfish |
| G03 | â¬œ Blancs | âŒ DÃ©faite | ~186 | 86 | Perd en milieu de partie |
| G04 | â¬› Noirs | âŒ DÃ©faite | ~49 | 35-51 | DÃ©faite rapide |
| G05 | â¬œ Blancs | âŒ DÃ©faite | ~138 | 31 | Sacrifice incorrect par la recherche |
| G06 | â¬› Noirs | âŒ DÃ©faite | ~54 | 71 | Perd du matÃ©riel tÃ´t |
| G07 | â¬œ Blancs | âŒ DÃ©faite | ~238 | 160 | Longue partie, pas de plan |
| G08 | â¬› Noirs | âŒ DÃ©faite | ~43 | 35 | Mat rapide |
| G09 | â¬œ Blancs | âŒ DÃ©faite | ~134 | 29 | Recherche peu profonde |
| G10 | â¬› Noirs | âŒ DÃ©faite | ~50 | 125 | Perd en milieu de partie |

**Score : 0W - 0D - 10L = 0.0/10 (0%) â€” Elo estimÃ© : ~950**

#### Benchmark comparatif

| MÃ©trique | InstantanÃ© | Recherche d=4 n=1000 |
|----------|-----------|---------------------|
| Victoires | 0 | 0 |
| Nulles | 1 | 0 |
| DÃ©faites | 9 | 10 |
| Win rate | 5% | 0% |
| Elo estimÃ© | ~838 | ~950 |
| DurÃ©e moyenne/partie | **155 demi-coups** | **109 demi-coups** |
| Score interne typique | `+0.0` (constant) | oscillant (`-1.9` Ã  `+8.3`) |

### Graphiques de matÃ©riel

Les graphiques ci-dessous montrent l'Ã©volution du matÃ©riel (en points : pion=1, cavalier/fou=3,
tour=5, dame=9) au cours de chaque partie. La ligne bleue reprÃ©sente l'avantage matÃ©riel du
point de vue du rÃ©seau.

**Mode instantanÃ© :**

![MatÃ©riel instantanÃ©](instant_material.png)

**Mode recherche :**

![MatÃ©riel recherche](search_d4_material.png)

### Analyse approfondie des parties

#### SymptÃ´me nÂ°1 : le rÃ©seau perd du matÃ©riel sans le savoir

Dans la partie G09 (mode instantanÃ©), le rÃ©seau joue les Blancs et se retrouve avec un dÃ©ficit
matÃ©riel de Î”-16 (1 point de matÃ©riel blanc contre 17 points noirs â€” Stockfish a rÃ©cupÃ©rÃ©
quasiment toutes les piÃ¨ces). MalgrÃ© cette situation catastrophique, le score interne du rÃ©seau
reste `sc=+0.0` Ã  chaque coup. Le rÃ©seau continue de jouer "normalement", dÃ©plaÃ§ant son roi
sans aucune conscience que la partie est perdue.

```
G09 â”‚  43.f2g3   ğŸ¤– â”‚ mat â¬œ 2 â¬›17 Î”-15 â”‚ legal= 35 â”‚ d= 0 n=1 sc=+0.0
G09 â”‚  44.g3f4   ğŸ¤– â”‚ mat â¬œ 1 â¬›17 Î”-16 â”‚ legal= 42 â”‚ d= 0 n=1 sc=+0.0
G09 â”‚  45.f4e4   ğŸ¤– â”‚ mat â¬œ 1 â¬›17 Î”-16 â”‚ legal= 37 â”‚ d= 0 n=1 sc=+0.0
```

**Explication :** le rÃ©seau ne prÃ©dit que le prochain coup probable, pas la qualitÃ© de la position.
Il n'a aucune notion de "gagner" ou "perdre" â€” il joue comme s'il rÃ©citait des coups appris par cÅ“ur.

#### SymptÃ´me nÂ°2 : avantage matÃ©riel non converti

Dans la partie G04 (mode instantanÃ©), le rÃ©seau joue les Noirs et se retrouve paradoxalement
avec **+12 points de matÃ©riel d'avance** (il a beaucoup plus de piÃ¨ces que Stockfish). Mais il
est incapable de convertir cet avantage en mat. Il promÃ¨ne ses piÃ¨ces sans plan pendant 66 coups
jusqu'Ã  ce que Stockfish, malgrÃ© son handicap matÃ©riel, trouve un mat tactique.

**Explication :** savoir quel coup un GM jouerait â‰  comprendre pourquoi il le joue. Le rÃ©seau
imite des patterns de coups sans comprendre les objectifs stratÃ©giques sous-jacents (centraliser,
couper le roi adverse, coordonner les piÃ¨ces pour le mat).

#### SymptÃ´me nÂ°3 : la recherche alpha-beta n'aide pas

Contre-intuitivement, le mode recherche (Elo ~950) fait **moins bien** que le mode instantanÃ©
(Elo ~838) en termes de nulles (0 vs 1). La recherche rend les parties plus courtes (109 vs 155
demi-coups) car elle "s'engage" avec plus de confiance dans des lignes qu'elle estime favorables â€”
mais son Ã©valuation est erronÃ©e.

L'Ã©valuation alpha-beta combine le score matÃ©riel et la mobilitÃ© avec un bonus de probabilitÃ©
issu du rÃ©seau. Mais le rÃ©seau attribue des probabilitÃ©s Ã©levÃ©es Ã  des coups "typiques de GM"
qui ne sont pas forcÃ©ment bons dans la position donnÃ©e. La recherche amplifie ces biais au lieu
de les corriger.

Le score interne oscille de faÃ§on erratique : `-1.9` â†’ `+8.3` â†’ `-1.5` sur des coups successifs
dans la mÃªme partie (G01). Cela montre que la fonction d'Ã©valuation n'est pas cohÃ©rente et ne
peut pas guider efficacement un arbre de recherche.

### Pourquoi la recherche n'aide pas (encore)

La recherche alpha-beta est un multiplicateur de force â€” elle amplifie la qualitÃ© de la fonction
d'Ã©valuation. Si l'Ã©valuation est bonne (comme dans Stockfish), la recherche est extrÃªmement
puissante. Si l'Ã©valuation est incohÃ©rente (comme notre rÃ©seau), la recherche amplifie les erreurs.

Pour que la recherche devienne utile, il faudrait :
1. **Une tÃªte d'Ã©valuation** : entraÃ®ner le rÃ©seau Ã  prÃ©dire non seulement le prochain coup
   mais aussi le rÃ©sultat de la partie (victoire/nulle/dÃ©faite). Cela donnerait un vrai score
   positionnel pour guider la recherche.
2. **Une meilleure prÃ©cision top-1** : avec 24.8%, le rÃ©seau se trompe 3 fois sur 4. Au-dessus
   de ~35%, les erreurs deviennent rares et la recherche peut les compenser.

---

## 6. Fichiers de sortie

### Structure des rÃ©sultats

Chaque exÃ©cution de l'Ã©valuation produit un ensemble complet de fichiers horodatÃ©s dans un
sous-dossier dÃ©diÃ©. L'horodatage garantit que les rÃ©sultats ne sont jamais Ã©crasÃ©s, permettant
de comparer les performances entre diffÃ©rentes versions du modÃ¨le.

```
chess-gpu/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/                              # code partagÃ© entre phases
â”‚   â”‚   â”œâ”€â”€ download_data.py                 # tÃ©lÃ©chargement PGN Chess.com
â”‚   â”‚   â””â”€â”€ prepare_data.py                  # PGN â†’ vecteurs .npz
â”‚   â”œâ”€â”€ phase1_mlp/                          # rÃ©seau feedforward (cette phase)
â”‚   â”‚   â”œâ”€â”€ main.py                          # orchestrateur pipeline
â”‚   â”‚   â”œâ”€â”€ train_torch.py                   # entraÃ®nement PyTorch (GPU)
â”‚   â”‚   â”œâ”€â”€ train.py                         # ancien modÃ¨le linÃ©aire (archive)
â”‚   â”‚   â””â”€â”€ evaluate.py                      # Ã©valuation vs Stockfish
â”‚   â””â”€â”€ phase2_transformer/                  # futur â€” architecture Transformer
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ phase1_mlp/
â”‚       â”œâ”€â”€ results.md                       # ce document
â”‚       â”œâ”€â”€ training_curves.png              # courbes loss/accuracy
â”‚       â”œâ”€â”€ instant_material.png             # graphique matÃ©riel (mode instantanÃ©)
â”‚       â”œâ”€â”€ instant_summary.json             # rÃ©sumÃ© JSON (mode instantanÃ©)
â”‚       â”œâ”€â”€ instant_games.html               # visualisation interactive
â”‚       â”œâ”€â”€ search_d4_material.png           # graphique matÃ©riel (recherche d=4)
â”‚       â”œâ”€â”€ search_d4_summary.json           # rÃ©sumÃ© JSON (recherche d=4)
â”‚       â””â”€â”€ search_d4_games.html             # visualisation interactive
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ king_matrix.md                       # thÃ©orie matricielle du roi
â”‚   â””â”€â”€ model.md                             # thÃ©orie du modÃ¨le linÃ©aire
â”‚
â”œâ”€â”€ data/                                    # donnÃ©es (gitignored)
â”‚   â”œâ”€â”€ top_players.pgn                      # 598.5 Mo â€” parties brutes
â”‚   â”œâ”€â”€ top_players.npz                      # 256.9 Mo â€” donnÃ©es encodÃ©es
â”‚   â”œâ”€â”€ top_players_model.npz                # 7.2 Mo  â€” poids du rÃ©seau
â”‚   â””â”€â”€ top_players_model_checkpoint.pt      # 7.8 Mo  â€” checkpoint PyTorch
â”‚
â”œâ”€â”€ run_colab.py                             # script tout-en-un Colab
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Format du JSON de rÃ©sumÃ©

```json
{
  "model": "data/top_players_model.npz",
  "mode": "instantanÃ©",
  "max_depth": 0,
  "max_nodes": 0,
  "stockfish_elo": 1350,
  "estimated_elo": 950,
  "n_games": 10,
  "wins": 0,
  "draws": 0,
  "losses": 10,
  "score": 0.0,
  "win_rate": 0.0,
  "workers": 8,
  "tag": "20260215_175526_instantanÃ©"
}
```

### Format du log (extrait)

Chaque ligne du log contient : le numÃ©ro de partie, le coup jouÃ©, l'identitÃ© du joueur
(ğŸ¤– rÃ©seau ou â™Ÿ Stockfish), le matÃ©riel de chaque camp, la profondeur de recherche atteinte,
le nombre de nÅ“uds explorÃ©s et le score Ã©valuÃ©.

```
G04 â”‚  55...f3e4   ğŸ¤– â”‚ mat â¬œ12 â¬› 0 Î”+12 â”‚ legal= 26 â”‚ d=0 n=1 fw=1 sc=+0.0 t=0.00s
G04 â”‚  56.c2c4    â™Ÿ â”‚ mat â¬œ12 â¬› 0 Î”+12 â”‚ legal=  5 â”‚                     stockfish
```

---

## 7. Performance de la pipeline

### Temps d'exÃ©cution dÃ©taillÃ©

| Ã‰tape | DurÃ©e | DÃ©tail |
|-------|-------|--------|
| Installation Stockfish | ~5 s | `apt install -y stockfish` |
| Clone du repo + dÃ©pendances | ~15 s | `git clone` + `pip install -r requirements.txt` |
| TÃ©lÃ©chargement PGN | **~15 min** | 10 joueurs Ã— 8 workers parallÃ¨les, 598.5 Mo total |
| Lecture et dÃ©coupage du PGN | **0.9 s** | `_split_pgn()` : lecture sÃ©quentielle du fichier 598 Mo |
| Parsing et encodage | **86 s** | 208k parties â†’ 17.7M exemples, 8 workers ProcessPoolExecutor |
| Sauvegarde NPZ | ~5 s | Compression de 17.7M Ã— 832 uint8 â†’ 256.9 Mo |
| Chargement sur GPU | ~10 s | Transfert de 27.5 Go (float32) du CPU vers la VRAM |
| EntraÃ®nement | **2 min 48 s** | 50 epochs Ã— 2.9s, batch=8192, AMP, torch.compile |
| Export modÃ¨le | ~1 s | Checkpoint .pt (7.8 Mo) + export .npz (7.2 Mo) |
| Ã‰valuation instantanÃ©e | **~10 s** | 10 parties en parallÃ¨le (8 workers) |
| Ã‰valuation recherche | **~20 s** | 10 parties, depth=4, 1000 nÅ“uds/coup |
| Benchmark | **~30 s** | 2Ã—10 parties (instantanÃ© + recherche) |
| **Total (premiÃ¨re exÃ©cution)** | **~20 min** | Avec tÃ©lÃ©chargement des donnÃ©es |
| **Total (relance)** | **~3 min** | EntraÃ®nement + Ã©valuations seulement |

### RÃ©partition du temps (premiÃ¨re exÃ©cution)

```
TÃ©lÃ©chargement   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  75%  (~15 min)
Parsing          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                      6%  (86 s)
EntraÃ®nement     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                    9%  (2 min 48 s)
Ã‰valuations      â–ˆâ–ˆâ–ˆ                                        5%  (~60 s)
Divers           â–ˆâ–ˆ                                         5%  (~60 s)
```

Le tÃ©lÃ©chargement depuis Chess.com domine largement. En relance (donnÃ©es dÃ©jÃ  tÃ©lÃ©chargÃ©es),
l'entraÃ®nement prend 90% du temps.

---

## 8. Stack technique

| Composant | Technologie | RÃ´le |
|-----------|-------------|------|
| Langage | Python 3.12 | Orchestration et logique mÃ©tier |
| Deep Learning | PyTorch 2.0+ | EntraÃ®nement du rÃ©seau (CUDA, AMP, torch.compile) |
| InfÃ©rence GPU | CuPy | InfÃ©rence NumPy-compatible sur GPU pendant l'Ã©valuation |
| Ã‰checs | python-chess | ReprÃ©sentation du plateau, validation des coups, parsing PGN |
| Adversaire | Stockfish 14 | Moteur d'Ã©valuation limitÃ© Ã  Elo 1350 |
| Calcul matriciel | NumPy | Encodage des positions, export du modÃ¨le |
| ParallÃ©lisme | ProcessPoolExecutor, ThreadPoolExecutor | Parsing PGN (multiprocess) et parties d'Ã©valuation (multithreaded) |
| Environnement | Google Colab | GPU cloud (RTX PRO 6000 Blackwell, 95 Go VRAM) |
| Versioning | Git + GitHub | Code source et rÃ©sultats |
| Automatisation | `run_colab.py` | Script tout-en-un adaptatif pour Colab |

### DÃ©pendances Python

```
torch>=2.0
chess
numpy
matplotlib
```

---

## 9. Pistes d'amÃ©lioration

### Gains rapides (faible effort, impact modÃ©rÃ©)

| Piste | Impact attendu | Explication |
|-------|---------------|-------------|
| **Plus d'epochs (100-200)** | Top-1 ~26-28% | La val loss baissait encore Ã  epoch 50, le modÃ¨le n'a pas convergÃ©. Un cosine restart sur 200 epochs devrait donner 2-3% de plus. |
| **RÃ©seau plus large** (2048â†’1024â†’512â†’256) | Top-1 ~27-30% | Le modÃ¨le actuel (2M params) est petit. Doubler la premiÃ¨re couche ajoute ~1.7M params et exploite mieux les 17.7M exemples. |
| **Augmenter les parties de jeu** | Meilleure gÃ©nÃ©ralisation | TÃ©lÃ©charger 50 joueurs au lieu de 10 pour diversifier les styles et atteindre 500k+ parties. |

### Gains structurels (effort moyen, impact fort)

| Piste | Impact attendu | Explication |
|-------|---------------|-------------|
| **Encoder les mÃ©tadonnÃ©es** | +1-2% top-1 | Ajouter au vecteur d'entrÃ©e : le tour de jeu (1 bit), les droits de roque (4 bits), la case d'en-passant (6 bits). Passe de 832D Ã  ~845D. |
| **TÃªte d'Ã©valuation** | Score fiable pour Î±-Î² | Ajouter une sortie auxiliaire au rÃ©seau prÃ©disant le rÃ©sultat de la partie (Win/Draw/Loss). L'entraÃ®ner avec les rÃ©sultats des parties (disponibles dans le PGN). Cela donnerait un vrai score positionnel pour la recherche alpha-beta. |
| **CNN sur l'Ã©chiquier 8Ã—8** | Capture les patterns spatiaux | ReprÃ©senter l'Ã©chiquier comme une image 8Ã—8Ã—13 et utiliser des convolutions. Les CNN capturent naturellement les structures spatiales (colonnes ouvertes, diagonales, structures de pions). |

### Gains majeurs (effort Ã©levÃ©, impact transformateur)

| Piste | Impact attendu | Explication |
|-------|---------------|-------------|
| **Architecture Transformer** | State-of-the-art | L'attention multi-tÃªte permet de capturer les relations Ã  longue distance entre les piÃ¨ces (menaces, dÃ©fenses, coordination). C'est l'approche d'AlphaZero/Leela Chess Zero. |
| **Self-play + MCTS** | Elo +200-400 | EntraÃ®ner le rÃ©seau Ã  jouer contre lui-mÃªme avec Monte Carlo Tree Search (comme AlphaZero). Le rÃ©seau s'amÃ©liore de faÃ§on autonome, sans donnÃ©es humaines. |
| **RÃ©seau d'Ã©valuation dÃ©diÃ©** | Recherche efficace | SÃ©parer le rÃ©seau de prÃ©diction de coups (policy head) et le rÃ©seau d'Ã©valuation (value head) comme dans AlphaZero. |

---

## 10. Conclusion

### Ce qui fonctionne

Ce projet dÃ©montre qu'il est possible de construire un joueur d'Ã©checs fonctionnel **en partant
de zÃ©ro**, sans aucune connaissance codÃ©e en dur, avec seulement **3 minutes de calcul GPU**
et **17.7 millions de positions** de Grands MaÃ®tres. Le rÃ©seau atteint **24.8% de prÃ©cision top-1**
(496Ã— mieux que le hasard) et **52.5% de top-5** â€” il joue des coups raisonnables dans la majoritÃ©
des positions.

La pipeline est rapide et reproductible : tÃ©lÃ©chargement parallÃ¨le (~15 min), parsing optimisÃ©
(86s), entraÃ®nement sur GPU (2 min 48 s). Le tout est automatisÃ© dans un script unique pour
Google Colab.

### Ce qui ne fonctionne pas encore

Le rÃ©seau ne bat pas Stockfish, mÃªme bridÃ© Ã  1350 Elo. Les causes sont identifiÃ©es :

1. **Pas de conscience positionnelle** â€” le rÃ©seau prÃ©dit des coups sans comprendre leur but
   stratÃ©gique. Il peut avoir un avantage matÃ©riel Ã©crasant et ne pas savoir le convertir.
2. **La recherche alpha-beta est contreproductive** â€” sans fonction d'Ã©valuation fiable, elle
   amplifie les erreurs du rÃ©seau au lieu de les compenser.
3. **L'encodage est incomplet** â€” le vecteur 832D ne contient ni le tour de jeu, ni les droits
   de roque, ni l'en-passant, ce qui prive le rÃ©seau d'informations cruciales.

### Le goulot d'Ã©tranglement

Le goulot d'Ã©tranglement n'est plus le calcul. GrÃ¢ce aux optimisations GPU (dataset en VRAM, AMP,
batch=8192), l'entraÃ®nement ne prend que 3 minutes pour 50 epochs. Le vrai dÃ©fi est la
**reprÃ©sentation** : un MLP plat avec un encodage one-hot ne peut pas capturer les structures
spatiales et les relations stratÃ©giques complexes des Ã©checs.

Les prochaines Ã©tapes â€” tÃªte d'Ã©valuation positionnelle, encodage enrichi, et architecture
spatiale (CNN ou Transformer) â€” devraient permettre de franchir la barre des **1000 Elo**
et de rendre la recherche alpha-beta enfin utile.

---

## Annexe : Commandes Colab

### ExÃ©cution complÃ¨te

```bash
cd /content && python chess-gpu/run_colab.py
```

### Copier les rÃ©sultats dans le repo pour les versionner

```bash
mkdir -p /content/chess-gpu/results/phase1_mlp
cp /content/chess-gpu/data/top_players_model_curves.png /content/chess-gpu/results/phase1_mlp/training_curves.png
cp /content/chess-gpu/data/top_players_model_runs/*instantanÃ©*_material.png /content/chess-gpu/results/phase1_mlp/instant_material.png
cp /content/chess-gpu/data/top_players_model_runs/*instantanÃ©*_summary.json /content/chess-gpu/results/phase1_mlp/instant_summary.json
cp /content/chess-gpu/data/top_players_model_runs/*instantanÃ©*_games.html /content/chess-gpu/results/phase1_mlp/instant_games.html
cp /content/chess-gpu/data/top_players_model_runs/*recherche*_material.png /content/chess-gpu/results/phase1_mlp/search_d4_material.png
cp /content/chess-gpu/data/top_players_model_runs/*recherche*_summary.json /content/chess-gpu/results/phase1_mlp/search_d4_summary.json
cp /content/chess-gpu/data/top_players_model_runs/*recherche*_games.html /content/chess-gpu/results/phase1_mlp/search_d4_games.html
cd /content/chess-gpu && git add results/ && git commit -m "docs: add phase1 results" && git push
```

### Monitoring GPU

```python
import subprocess, time, datetime
print(f"{'Heure':>10} â”‚ {'GPU %':>5} â”‚ {'VRAM MiB':>14} â”‚ {'Power W':>12} â”‚ {'Temp':>5}")
print("â”€" * 60)
try:
    while True:
        out = subprocess.check_output(
            ["nvidia-smi", "--query-gpu=utilization.gpu,memory.used,memory.total,power.draw,power.limit,temperature.gpu",
             "--format=csv,noheader,nounits"], text=True).strip()
        gpu, mem, mem_t, pwr, pwr_m, temp = [x.strip() for x in out.split(",")]
        ts = datetime.datetime.now().strftime("%H:%M:%S")
        print(f"{ts:>10} â”‚ {gpu:>4}% â”‚ {mem:>6}/{mem_t:>6} â”‚ {pwr:>5}/{pwr_m:>5} â”‚ {temp:>4}Â°C")
        time.sleep(5)
except KeyboardInterrupt:
    print("\nâ¹ Monitoring arrÃªtÃ©")
```

---

*Projet : [chess-gpu](https://github.com/knoel99/chess-gpu) â€” Run du 15 fÃ©vrier 2026 sur NVIDIA RTX PRO 6000 Blackwell (95 Go VRAM)*
